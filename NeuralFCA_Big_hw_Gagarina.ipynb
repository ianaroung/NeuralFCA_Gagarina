{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ianaroung/NeuralFCA_Gagarina/blob/main/NeuralFCA_Big_hw_Gagarina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fcapy[all]\n",
        "!pip install frozendict\n",
        "!pip install ipynb\n",
        "!pip install sparselinear\n",
        "!pip install bitsets\n",
        "!pip install bitarray\n",
        "import torch\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "id": "cuicenOBvdEQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ff26b41-23c0-4470-ed75-a8227aea968f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fcapy[all]\n",
            "  Downloading fcapy-0.1.4.3-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.9/162.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: fcapy 0.1.4.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (1.23.5)\n",
            "Collecting scikit-mine>=1 (from fcapy[all])\n",
            "  Downloading scikit_mine-1.0.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray>=2.5.1 (from fcapy[all])\n",
            "  Downloading bitarray-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.9/279.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (1.5.3)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (2.3.10)\n",
            "Collecting bitsets (from fcapy[all])\n",
            "  Downloading bitsets-0.8.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (1.10.13)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (3.7.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (3.2.1)\n",
            "Collecting caspailleur (from fcapy[all])\n",
            "  Downloading caspailleur-0.1.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from fcapy[all]) (7.7.1)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from scikit-mine>=1->fcapy[all]) (1.11.4)\n",
            "Collecting pyroaring>=0.3.4 (from scikit-mine>=1->fcapy[all])\n",
            "  Downloading pyroaring-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-mine>=1->fcapy[all]) (2.4.0)\n",
            "Collecting dataclasses>=0.6 (from scikit-mine>=1->fcapy[all])\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting wget>=3.2 (from scikit-mine>=1->fcapy[all])\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from scikit-mine>=1->fcapy[all]) (0.20.1)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from scikit-mine>=1->fcapy[all]) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fcapy[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fcapy[all]) (2023.3.post1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->fcapy[all]) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->fcapy[all]) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->fcapy[all]) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->fcapy[all]) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->fcapy[all]) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->fcapy[all]) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fcapy[all]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fcapy[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fcapy[all]) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fcapy[all]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fcapy[all]) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fcapy[all]) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fcapy[all]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->fcapy[all]) (4.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fcapy[all]) (3.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->fcapy[all]) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->fcapy[all]) (6.3.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->fcapy[all])\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->fcapy[all]) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->fcapy[all]) (1.16.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->fcapy[all]) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (3.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->fcapy[all]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->fcapy[all]) (0.2.12)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (4.0.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.13.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->fcapy[all]) (2.21)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=2a1bcb81848aa0c5d4aa88a25096f9cdb8842801e1a51108371b1a86fefd73f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, pyroaring, dataclasses, bitarray, jedi, bitsets, scikit-mine, caspailleur, fcapy\n",
            "Successfully installed bitarray-2.8.4 bitsets-0.8.4 caspailleur-0.1.3 dataclasses-0.6 fcapy-0.1.4.3 jedi-0.19.1 pyroaring-0.4.4 scikit-mine-1.0.0 wget-3.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (2.3.10)\n",
            "Collecting ipynb\n",
            "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: ipynb\n",
            "Successfully installed ipynb-0.5.1\n",
            "Collecting sparselinear\n",
            "  Downloading sparselinear-0.0.5-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sparselinear) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from sparselinear) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->sparselinear) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->sparselinear) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->sparselinear) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->sparselinear) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->sparselinear) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->sparselinear) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->sparselinear) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->sparselinear) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->sparselinear) (1.3.0)\n",
            "Installing collected packages: sparselinear\n",
            "Successfully installed sparselinear-0.0.5\n",
            "Requirement already satisfied: bitsets in /usr/local/lib/python3.10/dist-packages (0.8.4)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (2.8.4)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=495091 sha256=f987854c6d807747692f5897bba71942d5e93e39da2bcad997b8f002803c2607\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1035675 sha256=f91c6d54543b1d2dfb7fe0f594d46176b78c6c72e3ecad2df447703fa54303dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl size=690648 sha256=5ed583137e86a0aecb4cd8621708f56feb721ec4e50a29d4998ef105be7c563b\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/78/c3/536637b3cdcc3313aa5e8851a6c72b97f6a01877e68c7595e3\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-21x7o2ka\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-21x7o2ka\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 6544b1ed310b8d07438e96c009b13ca66ef2a654\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=1066583 sha256=536af2c2441781722104acd1edafbf4fd9295b1b977198d2e5b1759126ae67d8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hwqrx0di/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v12S4V2u8J0"
      },
      "source": [
        "# Import libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUEvmHBsu8J0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLvzJls4u8J2"
      },
      "outputs": [],
      "source": [
        "from fcapy.context import FormalContext\n",
        "from fcapy.lattice import ConceptLattice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh6ROPg2u8J3"
      },
      "outputs": [],
      "source": [
        "from fcapy.visualizer import LineVizNx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = (1,1,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python neural_lib.py install"
      ],
      "metadata": {
        "id": "YQ3bipivNZl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CreHYwWu8J3"
      },
      "outputs": [],
      "source": [
        "import neural_lib as nl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joqy7QCNu8J5"
      },
      "source": [
        "# Step 0. Binarize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the datasets:"
      ],
      "metadata": {
        "id": "7B6MYNg3wnPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv('hcvdat0.csv')\n",
        "data2 = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
        "data3 = pd.read_excel('Mesothelioma data set.xlsx')"
      ],
      "metadata": {
        "id": "mHGFrKzQyZ87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop missing values and preprocess some features."
      ],
      "metadata": {
        "id": "LrGoIn2MxbIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = data1.iloc[:,1:]\n",
        "data1 = data1.dropna()\n",
        "data1 = pd.get_dummies(data1, columns = ['Sex'])\n",
        "data1['Category'].replace(to_replace=['0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis'], value=[0, 0, 1, 2, 3], inplace = True)\n",
        "\n",
        "data2 = data2.dropna()\n",
        "\n",
        "data3 = data3.dropna()\n",
        "#Заменим в target 2 на 1\n",
        "data3.loc[data3['class of diagnosis'] == 2, 'class of diagnosis'] = 0"
      ],
      "metadata": {
        "id": "eihTISavyiXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first dataset, whose original target has 4 categories, one of which is healthy people (blood donors), and the other 3 categories are people with different stages of hepatitis C (initial stage, fibrosis and cirrhosis). Thus, we can replace it with 2 categories: people with hepatitis and healthy people."
      ],
      "metadata": {
        "id": "xrKncz-T32_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1.loc[data1['Category'] == 0, 'Category'] = 0\n",
        "data1.loc[data1['Category'] != 0, 'Category'] = 1"
      ],
      "metadata": {
        "id": "BfiW-F7bq4N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hepatitis C may be indicated by elevated levels of ALT, AST, bilirubin levels, GGT and sometimes creatinine. This information was found on the Internet but we can see it using the next code:"
      ],
      "metadata": {
        "id": "mBAfB54u42G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1.groupby(['Category']).mean()"
      ],
      "metadata": {
        "id": "SInj5RNmIodH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, for the df_bin1 we will use these features:"
      ],
      "metadata": {
        "id": "KjEpF69izmMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bin1 = data1[['ALT', 'AST', 'CREA', 'BIL', 'GGT', 'Category']]"
      ],
      "metadata": {
        "id": "L1qdk2qeI27v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bin1.loc[df_bin1['BIL'] >= 10, 'BIL'] = True\n",
        "df_bin1.loc[df_bin1['BIL'] < 10, 'BIL'] = False\n",
        "df_bin1.loc[df_bin1['ALT'] < 20, 'ALT'] = True\n",
        "df_bin1.loc[df_bin1['ALT'] >= 20, 'ALT'] = False\n",
        "df_bin1.loc[df_bin1['CREA'] < 100, 'CREA'] = True\n",
        "df_bin1.loc[df_bin1['CREA'] >= 100, 'CREA'] = False\n",
        "df_bin1.loc[df_bin1['AST'] < 50, 'AST'] = True\n",
        "df_bin1.loc[df_bin1['AST'] >= 50, 'AST'] = False\n",
        "df_bin1.loc[df_bin1['GGT'] >= 50, 'GGT'] = True\n",
        "df_bin1.loc[df_bin1['GGT'] < 50, 'GGT'] = False\n",
        "df_bin1 = df_bin1.replace({1: True, 0: False})\n",
        "df_bin1"
      ],
      "metadata": {
        "id": "kJkdgzR3JK2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For this dataset I leave two signs, since according to the study they are the most informative (https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5#Sec8). I also tried to add other features, but they were not important, the neurons mainly used these features, so I decided to split these features into more intervals and remove others so as not to unnecessarily complicate the model."
      ],
      "metadata": {
        "id": "CN8wxQ_JyQ6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2.groupby(['DEATH_EVENT']).mean()"
      ],
      "metadata": {
        "id": "ext0fnVILkmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bin2 = data2[['serum_creatinine', 'ejection_fraction', 'DEATH_EVENT']]"
      ],
      "metadata": {
        "id": "cgtJSFs93RE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bin2['ejection_fraction>20'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>20'] < 20, 'ejection_fraction>20'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>20'] >= 20, 'ejection_fraction>20'] = True\n",
        "\n",
        "df_bin2['ejection_fraction>30'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>30'] < 30, 'ejection_fraction>30'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>30'] >= 30, 'ejection_fraction>30'] = True\n",
        "\n",
        "df_bin2['ejection_fraction>38'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>38'] < 38, 'ejection_fraction>38'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>38'] >= 38, 'ejection_fraction>38'] = True\n",
        "\n",
        "df_bin2['ejection_fraction>45'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>45'] < 45, 'ejection_fraction>45'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>45'] >= 45, 'ejection_fraction>45'] = True\n",
        "\n",
        "df_bin2['ejection_fraction>50'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>50'] < 50, 'ejection_fraction>50'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>50'] >= 50, 'ejection_fraction>50'] = True\n",
        "\n",
        "df_bin2['ejection_fraction>55'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>55'] < 55, 'ejection_fraction>55'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>55'] >= 55, 'ejection_fraction>55'] = True\n",
        "\n",
        "df_bin2['ejection_fraction>60'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>60'] < 60, 'ejection_fraction>60'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>60'] >= 60, 'ejection_fraction>60'] = True\n",
        "\n",
        "df_bin2['ejection_fraction>70'] = df_bin2['ejection_fraction']\n",
        "df_bin2.loc[df_bin2['ejection_fraction>70'] < 70, 'ejection_fraction>70'] = False\n",
        "df_bin2.loc[df_bin2['ejection_fraction>70'] >= 70, 'ejection_fraction>70'] = True\n",
        "\n",
        "\n",
        "\n",
        "df_bin2['serum_creatinine<0.9'] = df_bin2['serum_creatinine']\n",
        "df_bin2.loc[df_bin2['serum_creatinine<0.9'] <= 0.9, 'serum_creatinine<0.9'] = True\n",
        "df_bin2.loc[df_bin2['serum_creatinine<0.9'] > 0.9, 'serum_creatinine<0.9'] = False\n",
        "\n",
        "df_bin2['serum_creatinine<1.1'] = df_bin2['serum_creatinine']\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.1'] <= 1.1, 'serum_creatinine<1.1'] = True\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.1'] > 1.1, 'serum_creatinine<1.1'] = False\n",
        "\n",
        "df_bin2['serum_creatinine<1.25'] = df_bin2['serum_creatinine']\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.25'] <= 1.25, 'serum_creatinine<1.25'] = True\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.25'] > 1.25, 'serum_creatinine<1.25'] = False\n",
        "\n",
        "df_bin2['serum_creatinine<1.4'] = df_bin2['serum_creatinine']\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.4'] <= 1.4, 'serum_creatinine<1.4'] = True\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.4'] > 1.4, 'serum_creatinine<1.4'] = False\n",
        "\n",
        "df_bin2['serum_creatinine<1.6'] = df_bin2['serum_creatinine']\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.6'] <= 1.6, 'serum_creatinine<1.6'] = True\n",
        "df_bin2.loc[df_bin2['serum_creatinine<1.6'] > 1.6, 'serum_creatinine<1.6'] = False\n",
        "\n",
        "df_bin2['serum_creatinine<2'] = df_bin2['serum_creatinine']\n",
        "df_bin2.loc[df_bin2['serum_creatinine<2'] <= 2, 'serum_creatinine<2'] = True\n",
        "df_bin2.loc[df_bin2['serum_creatinine<2'] > 2, 'serum_creatinine<2'] = False\n",
        "\n",
        "df_bin2['serum_creatinine<5'] = df_bin2['serum_creatinine']\n",
        "df_bin2.loc[df_bin2['serum_creatinine<5'] <= 5, 'serum_creatinine<5'] = True\n",
        "df_bin2.loc[df_bin2['serum_creatinine<5'] > 5, 'serum_creatinine<5'] = False\n",
        "\n",
        "df_bin2 = df_bin2.drop(['serum_creatinine'], axis=1)\n",
        "df_bin2 = df_bin2.drop(['ejection_fraction'], axis=1)\n",
        "\n",
        "df_bin2 = df_bin2.replace({1: True, 0: False})\n",
        "df_bin2"
      ],
      "metadata": {
        "id": "xHhCbi5sRmJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are quite a lot of features in the third dataset - 34, so you can just take all the binary ones, there are 13 of them."
      ],
      "metadata": {
        "id": "-qgPeaM_7QHr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHv87ygJu8J5"
      },
      "outputs": [],
      "source": [
        "df_bin3 = data3[['gender', 'asbestos exposure', 'diagnosis method', 'cytology', 'dyspnoea', 'ache on chest',\n",
        "                'weakness', 'performance status', 'hemoglobin (HGB)', 'dead or not', 'pleural effusion', 'pleural thickness on tomography',\n",
        "                'pleural level of acidity (pH)', 'class of diagnosis']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bin3 = df_bin3.replace({1: True, 0: False})\n",
        "df_bin3"
      ],
      "metadata": {
        "id": "OskeUKOe1scQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvmQkGnu8J6"
      },
      "source": [
        "Split the data to train and test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "mBy9aj3JiDXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = np.arange(0, 700)\n",
        "a = []\n",
        "for i in range(len(s)):\n",
        "  a.append(str(s[i]))"
      ],
      "metadata": {
        "id": "kHH9uT9QFA4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = df_bin1['Category']\n",
        "x1 = df_bin1.drop(['Category'], axis=1)"
      ],
      "metadata": {
        "id": "X-ISKigVtDjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1['id'] = a[:589]\n",
        "x1 = x1.set_index('id')"
      ],
      "metadata": {
        "id": "Viw9_sPStIg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "HTOh9StVtRqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkxmcv3iu8J6"
      },
      "outputs": [],
      "source": [
        "y2 = df_bin2['DEATH_EVENT']\n",
        "x2 = df_bin2.drop(['DEATH_EVENT'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2['id'] = a[:299]\n",
        "x2 = x2.set_index('id')"
      ],
      "metadata": {
        "id": "KWZZKwOPE7oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "vJPPnw9HiOBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = df_bin3['class of diagnosis']\n",
        "x3 = df_bin3.drop(['class of diagnosis'], axis=1)"
      ],
      "metadata": {
        "id": "YuhtVmJT7sJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x3['id'] = a[:324]\n",
        "x3 = x3.set_index('id')"
      ],
      "metadata": {
        "id": "iXfIrzFjFUng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "hA4RXT48iTAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obxf3WTzu8J6"
      },
      "source": [
        "## Step 1. Build Monotone Concept Lattice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFZ9pxGXu8J7"
      },
      "source": [
        "Put binarized data in FormalContext and compute monotone ConceptLattice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_train1 = FormalContext.from_pandas(X_train1)\n",
        "K_train1"
      ],
      "metadata": {
        "id": "gtFyjRuqtaga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s3nNfPCu8J7"
      },
      "outputs": [],
      "source": [
        "K_train2 = FormalContext.from_pandas(X_train2)\n",
        "K_train2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_train3 = FormalContext.from_pandas(X_train3)\n",
        "K_train3"
      ],
      "metadata": {
        "id": "CRDDTOqt_uL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1 = ConceptLattice.from_context(K_train1, is_monotone=True)\n",
        "len(L1)"
      ],
      "metadata": {
        "id": "zzh4nxI8teuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pXFHy-Hu8J7"
      },
      "outputs": [],
      "source": [
        "L2 = ConceptLattice.from_context(K_train2, is_monotone=True)\n",
        "len(L2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L3 = ConceptLattice.from_context(K_train3, is_monotone=True)\n",
        "len(L3)"
      ],
      "metadata": {
        "id": "qxEq_vBNFkPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DawYnkrju8J8"
      },
      "source": [
        "Compute F1 score for each formal concept  (assuming that an object is predicted True if it is in the extent of the concept)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "for c1 in L1:\n",
        "    y_preds1 = np.zeros(K_train1.n_objects)\n",
        "    y_preds1[list(c1.extent_i)] = 1\n",
        "    c1.measures['f1_score'] = f1_score(y_train1, y_preds1)"
      ],
      "metadata": {
        "id": "1WGPyajntiGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jr6a97Uu8J8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "for c2 in L2:\n",
        "    y_preds2 = np.zeros(K_train2.n_objects)\n",
        "    y_preds2[list(c2.extent_i)] = 1\n",
        "    c2.measures['f1_score'] = f1_score(y_train2, y_preds2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "for c3 in L3:\n",
        "    y_preds3 = np.zeros(K_train3.n_objects)\n",
        "    y_preds3[list(c3.extent_i)] = 1\n",
        "    c3.measures['f1_score'] = f1_score(y_train3, y_preds3)"
      ],
      "metadata": {
        "id": "-sZ9SH5UTEpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWFF79g1u8J8"
      },
      "source": [
        "Select indices of the best concepts from the lattice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_concepts1 = list(L1.measures['f1_score'].argsort()[::-1][3:4])\n",
        "\n",
        "# assert len({g_i for c in L1[best_concepts1] for g_i in c.extent_i})==K_train1.n_objects, \"Selected concepts do not cover all train objects\""
      ],
      "metadata": {
        "id": "E8pU2ByjtpGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_TSgE1tu8J8"
      },
      "outputs": [],
      "source": [
        "best_concepts2 = list(L2.measures['f1_score'].argsort()[::-1][:2])\n",
        "\n",
        "assert len({g_i for c in L2[best_concepts2] for g_i in c.extent_i})==K_train2.n_objects, \"Selected concepts do not cover all train objects\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_concepts3 = list(L3.measures['f1_score'].argsort()[::-1][:194])\n",
        "\n",
        "assert len({g_i for c in L3[best_concepts3] for g_i in c.extent_i})==K_train3.n_objects, \"Selected concepts do not cover all train objects\""
      ],
      "metadata": {
        "id": "shpV7tdcTLEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEbdcXTuu8J9"
      },
      "source": [
        "Construct neural network based on concept lattice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn1 = nl.ConceptNetwork.from_lattice(L1, best_concepts1, sorted(set(y_train1)))"
      ],
      "metadata": {
        "id": "dx0YlanytvpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m24Z9BF1u8J9"
      },
      "outputs": [],
      "source": [
        "cn2 = nl.ConceptNetwork.from_lattice(L2, best_concepts2, sorted(set(y_train2)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn3 = nl.ConceptNetwork.from_lattice(L3, best_concepts3, sorted(set(y_train3)))"
      ],
      "metadata": {
        "id": "g4PVWNGiTSCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECcFd7WNu8J9"
      },
      "source": [
        "Setup visuzalier for the architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vis1 = LineVizNx(node_label_font_size=14, node_label_func=lambda el_i, P: nl.zneuron_label_func(el_i, P, set(cn1.attributes))+'\\n\\n')"
      ],
      "metadata": {
        "id": "ttAOWTFUt0H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZCxWnGlu8J-"
      },
      "outputs": [],
      "source": [
        "vis2 = LineVizNx(node_label_font_size=14, node_label_func=lambda el_i, P: nl.zneuron_label_func(el_i, P, set(cn2.attributes))+'\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vis3 = LineVizNx(node_label_font_size=14, node_label_func=lambda el_i, P: nl.zneuron_label_func(el_i, P, set(cn3.attributes))+'\\n\\n')"
      ],
      "metadata": {
        "id": "8YUJQ375TXwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descr1 = {'BIL', 'ALT'}\n",
        "\n",
        "traced1 = cn1.trace_description(descr1, include_targets=False)"
      ],
      "metadata": {
        "id": "OF-TsFuat46T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjwsGnWgu8J_"
      },
      "outputs": [],
      "source": [
        "descr2 = {'serum_creatinine<1.4', 'ejection_fraction>30'}\n",
        "\n",
        "traced2 = cn2.trace_description(descr2, include_targets=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "descr3 = {'dead or not'}\n",
        "\n",
        "traced3 = cn3.trace_description(descr3, include_targets=False)"
      ],
      "metadata": {
        "id": "ortGqZazjVND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "\n",
        "vis1.draw_poset(\n",
        "    cn1.poset, ax=ax,\n",
        "    flg_node_indices=False,\n",
        "    node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn1.attributes), only_new_attrs=True)+'\\n\\n',\n",
        "    node_color=['darkblue' if el_i in traced1 else 'lightgray' for el_i in range(len(cn1.poset))]\n",
        ")\n",
        "plt.title(f'NN based on 353 best concepts from monotone concept lattice', loc='left', x=0.05, size=24)\n",
        "\n",
        "plt.text(max(vis1.mover.posx), min(vis1.mover.posy)-0.3, f'*Blue neurons are the ones activated by description {descr1}', fontsize=14, ha='right', color='dimgray')\n",
        "\n",
        "plt.subplots_adjust()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2bGVg7N6t-lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "\n",
        "vis2.draw_poset(\n",
        "    cn2.poset, ax=ax,\n",
        "    flg_node_indices=False,\n",
        "    node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn2.attributes), only_new_attrs=True)+'\\n\\n',\n",
        "    node_color=['darkblue' if el_i in traced2 else 'lightgray' for el_i in range(len(cn2.poset))]\n",
        ")\n",
        "plt.title(f'NN based on 180 best concepts from monotone concept lattice', loc='left', x=0.05, size=24)\n",
        "\n",
        "plt.text(max(vis2.mover.posx), min(vis2.mover.posy)-0.3, f'*Blue neurons are the ones activated by description {descr2}', fontsize=14, ha='right', color='dimgray')\n",
        "\n",
        "plt.subplots_adjust()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fzbWXlVrZYTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izLszKkXu8J_"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "\n",
        "vis3.draw_poset(\n",
        "    cn3.poset, ax=ax,\n",
        "    flg_node_indices=False,\n",
        "    node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn3.attributes), only_new_attrs=True)+'\\n\\n',\n",
        "    node_color=['darkblue' if el_i in traced3 else 'lightgray' for el_i in range(len(cn3.poset))]\n",
        ")\n",
        "plt.title(f'NN based on 194 best concepts from monotone concept lattice', loc='left', x=0.05, size=24)\n",
        "\n",
        "plt.text(max(vis3.mover.posx), min(vis3.mover.posy)-0.3, f'*Blue neurons are the ones activated by description {descr3}', fontsize=14, ha='right', color='dimgray')\n",
        "\n",
        "plt.subplots_adjust()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPrsmFfRu8KA"
      },
      "source": [
        "Now fit the network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn1.fit(X_train1, y_train1)"
      ],
      "metadata": {
        "id": "vcRWO8VAuL0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cn2.fit(X_train2, y_train2)"
      ],
      "metadata": {
        "id": "h68x1xK-Zrcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7g8i3ecu8KA"
      },
      "outputs": [],
      "source": [
        "cn3.fit(X_train3, y_train3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7h8bK8Zu8KA"
      },
      "source": [
        "To obtain the prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Class prediction', cn1.predict(X_test1).numpy())\n",
        "print('Class prediction with probabilities', cn1.predict_proba(X_test1).detach().numpy())\n",
        "print('True class', y_test1.values)"
      ],
      "metadata": {
        "id": "zJzfcgn3uPjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(cn1.predict(X_test1).numpy() == y_test1).sum()/len(y_test1)"
      ],
      "metadata": {
        "id": "OBUkfMFzurGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test1, cn1.predict(X_test1).numpy())"
      ],
      "metadata": {
        "id": "eU09LxxZJ9Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Class prediction', cn2.predict(X_test2).numpy())\n",
        "print('Class prediction with probabilities', cn2.predict_proba(X_test2).detach().numpy())\n",
        "print('True class', y_test2.values)"
      ],
      "metadata": {
        "id": "jaNPDxsdZuKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test2, cn2.predict(X_test2).numpy())"
      ],
      "metadata": {
        "id": "3X2aOd0xkx5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(cn2.predict(X_test2).numpy() == y_test2).sum()/len(y_test2)"
      ],
      "metadata": {
        "id": "Tt4hVhu-vB0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v20CoH4cu8KG"
      },
      "outputs": [],
      "source": [
        "print('Class prediction', cn3.predict(X_test3).numpy())\n",
        "print('Class prediction with probabilities', cn3.predict_proba(X_test3).detach().numpy())\n",
        "print('True class', y_test3.values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test3, cn3.predict(X_test3).numpy())"
      ],
      "metadata": {
        "id": "kVrQqLfykqG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(cn3.predict(X_test3).numpy() == y_test3).sum()/len(y_test3)"
      ],
      "metadata": {
        "id": "VhWj9uPRvFty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the model predicts perfect the third dataset."
      ],
      "metadata": {
        "id": "dDk7JOmTvZh8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMye6Bv5u8KG"
      },
      "source": [
        "Let us look at the fitted weights of edges"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_weights1 = cn1.edge_weights_from_network()"
      ],
      "metadata": {
        "id": "hYPQ-vpyvKWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_weights2 = cn2.edge_weights_from_network()"
      ],
      "metadata": {
        "id": "ZA8tKf49Z2Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUOWnnwdu8KH"
      },
      "outputs": [],
      "source": [
        "edge_weights3 = cn3.edge_weights_from_network()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "\n",
        "vis1.draw_poset(\n",
        "    cn1.poset, ax=ax,\n",
        "    flg_node_indices=False,\n",
        "    node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn1.attributes), only_new_attrs=True)+'\\n\\n',\n",
        "    edge_color=[edge_weights1[edge] for edge in cn1.poset.to_networkx().edges],\n",
        "    edge_cmap=plt.cm.RdBu,\n",
        ")\n",
        "nx.draw_networkx_edge_labels(cn1.poset.to_networkx(), vis1.mover.pos, {k: f\"{v:.1f}\" for k,v in edge_weights1.items()}, label_pos=0.7)\n",
        "\n",
        "plt.title('Neural network with fitted edge weights', size=24, x=0.05, loc='left')\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust()\n",
        "plt.savefig('fitted_network.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KyV4Ptt7vNDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQSb6l_nu8KH"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "\n",
        "vis2.draw_poset(\n",
        "    cn2.poset, ax=ax,\n",
        "    flg_node_indices=False,\n",
        "    node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn2.attributes), only_new_attrs=True)+'\\n\\n',\n",
        "    edge_color=[edge_weights2[edge] for edge in cn2.poset.to_networkx().edges],\n",
        "    edge_cmap=plt.cm.RdBu,\n",
        ")\n",
        "nx.draw_networkx_edge_labels(cn2.poset.to_networkx(), vis2.mover.pos, {k: f\"{v:.1f}\" for k,v in edge_weights2.items()}, label_pos=0.7)\n",
        "\n",
        "plt.title('Neural network with fitted edge weights', size=24, x=0.05, loc='left')\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust()\n",
        "plt.savefig('fitted_network.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "\n",
        "vis3.draw_poset(\n",
        "    cn3.poset, ax=ax,\n",
        "    flg_node_indices=False,\n",
        "    node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn3.attributes), only_new_attrs=True)+'\\n\\n',\n",
        "    edge_color=[edge_weights3[edge] for edge in cn3.poset.to_networkx().edges],\n",
        "    edge_cmap=plt.cm.RdBu,\n",
        ")\n",
        "nx.draw_networkx_edge_labels(cn3.poset.to_networkx(), vis3.mover.pos, {k: f\"{v:.1f}\" for k,v in edge_weights3.items()}, label_pos=0.7)\n",
        "\n",
        "plt.title('Neural network with fitted edge weights', size=24, x=0.05, loc='left')\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust()\n",
        "plt.savefig('fitted_network.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "znxAIULTUAvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a good model but because of a lot of attributes the graph does not look pretty."
      ],
      "metadata": {
        "id": "HrZ_42ucvu83"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}